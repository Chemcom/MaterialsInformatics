{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sp8rks/MaterialsInformatics/blob/main/worked_examples/hyperparameter_opt/materials_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELFcx4WgrdXV"
   },
   "source": [
    "# Grid vs. Random Search Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrA6ZaIYhd7l"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyPdG8IxhbwG"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Tt5zD4rfeavx",
    "outputId": "451fa766-3241-4b77-f7db-bfbe464b98dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matbench in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (0.5)\n",
      "Requirement already satisfied: matminer==0.7.4 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matbench) (0.7.4)\n",
      "Requirement already satisfied: monty==2021.8.17 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matbench) (2021.8.17)\n",
      "Requirement already satisfied: scikit-learn==1.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matbench) (1.0)\n",
      "Requirement already satisfied: six>=1.16.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (1.16.0)\n",
      "Requirement already satisfied: pymongo>=3.12.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (4.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (2.27.1)\n",
      "Requirement already satisfied: future>=0.18.2 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (0.18.2)\n",
      "Requirement already satisfied: pymatgen>=2022.0.11 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (2022.2.7)\n",
      "Requirement already satisfied: sympy>=1.8 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (1.8)\n",
      "Requirement already satisfied: pint>=0.17 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (0.18)\n",
      "Requirement already satisfied: pandas>=1.3.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (1.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.2.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matminer==0.7.4->matbench) (1.22.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from scikit-learn==1.0->matbench) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from scikit-learn==1.0->matbench) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from scikit-learn==1.0->matbench) (3.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (0.18.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (52.0.0.post20210125)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (21.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pandas>=1.3.1->matminer==0.7.4->matbench) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pandas>=1.3.1->matminer==0.7.4->matbench) (2021.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pint>=0.17->matminer==0.7.4->matbench) (21.0)\n",
      "Requirement already satisfied: uncertainties>=3.1.4 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (3.1.5)\n",
      "Requirement already satisfied: spglib>=1.9.9.44 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (1.16.1)\n",
      "Requirement already satisfied: ruamel.yaml>=0.15.6 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (0.17.10)\n",
      "Requirement already satisfied: matplotlib>=1.5 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (3.4.2)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (2.5.1)\n",
      "Requirement already satisfied: Cython>=0.29.23 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (0.29.27)\n",
      "Requirement already satisfied: plotly>=4.5.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (5.1.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (0.8.9)\n",
      "Requirement already satisfied: pybtex in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (0.24.0)\n",
      "Requirement already satisfied: palettable>=3.1.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (3.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matplotlib>=1.5->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matplotlib>=1.5->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (8.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matplotlib>=1.5->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from matplotlib>=1.5->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (2.4.7)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from networkx>=2.2->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (4.4.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from plotly>=4.5.0->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (7.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2.10)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from ruamel.yaml>=0.15.6->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from sympy>=1.8->matminer==0.7.4->matbench) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from tqdm>=4.62.0->matminer==0.7.4->matbench) (0.4.4)\n",
      "Requirement already satisfied: PyYAML>=3.01 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pybtex->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (5.4.1)\n",
      "Requirement already satisfied: latexcodec>=1.0.4 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pybtex->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (2.0.1)\n",
      "Requirement already satisfied: CBFV in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from CBFV) (6.2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from CBFV) (1.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from CBFV) (4.62.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from CBFV) (1.22.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pandas->CBFV) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pandas->CBFV) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->CBFV) (1.16.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pytest->CBFV) (1.4.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pytest->CBFV) (0.13.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pytest->CBFV) (21.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pytest->CBFV) (0.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pytest->CBFV) (21.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iniconfig in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pytest->CBFV) (1.1.1)\n",
      "Requirement already satisfied: toml in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pytest->CBFV) (0.10.2)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from pytest->CBFV) (1.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from packaging->pytest->CBFV) (2.4.7)\n",
      "Requirement already satisfied: torch in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from torch) (4.1.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.3-cp39-cp39-win_amd64.whl (947 kB)\n",
      "Requirement already satisfied: torch==1.10.2 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from torchvision) (1.10.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from torchvision) (8.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from torchvision) (1.22.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\taylo\\miniconda3\\envs\\my_pymatgen\\lib\\site-packages (from torch==1.10.2->torchvision) (4.1.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matbench\n",
    "!pip install CBFV\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVTbZicohiDd"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yXjOg8s6ehcm"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11664/2833495345.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m \u001b[1;31m# All functions that don't have any parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m \u001b[1;31m# Gives easier dataset managment and creates mini batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;31m# Has standard datasets we can import in a nice and easy way\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[1;31m# Transformations we can perform on our dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F # All functions that don't have any parameters\n",
    "from torch.utils.data import DataLoader # Gives easier dataset managment and creates mini batches\n",
    "import torchvision.datasets as datasets # Has standard datasets we can import in a nice and easy way\n",
    "import torchvision.transforms as transforms # Transformations we can perform on our dataset\n",
    "\n",
    "from matbench.bench import MatbenchBenchmark\n",
    "from CBFV.composition import generate_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT51Iu3zhjJ8"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7hygIC8fGb9",
    "outputId": "98d10ff3-7c3f-4e1d-a1b2-4aa727ae9562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-09 21:36:57 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n",
      "['matbench_expt_is_metal']\n",
      "2022-02-09 21:36:57 INFO     Loading dataset 'matbench_expt_is_metal'...\n",
      "Fetching matbench_expt_is_metal.json.gz from https://ml.materialsproject.org/projects/matbench_expt_is_metal.json.gz to /usr/local/lib/python3.7/dist-packages/matminer/datasets/matbench_expt_is_metal.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching https://ml.materialsproject.org/projects/matbench_expt_is_metal.json.gz in MB: 0.034816MB [00:00, 40.50MB/s]                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-09 21:36:57 INFO     Dataset 'matbench_expt_is_metal loaded.\n",
      "mbid\n",
      "mb-expt-is-metal-0001      Ag(AuS)2\n",
      "mb-expt-is-metal-0002    Ag(W3Br7)2\n",
      "Name: composition, dtype: object mbid\n",
      "mb-expt-is-metal-0001    True\n",
      "mb-expt-is-metal-0002    True\n",
      "Name: is_metal, dtype: bool\n",
      "(3936,) (985,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mb = MatbenchBenchmark(subset=[\"matbench_expt_is_metal\"])\n",
    "task = list(mb.tasks)[0]\n",
    "task.load()\n",
    "fold0 = task.folds[0]\n",
    "train_inputs, train_outputs = task.get_train_and_val_data(fold0)\n",
    "test_inputs, test_outputs = task.get_test_data(fold0, include_target=True)\n",
    "print(train_inputs[0:2], train_outputs[0:2])\n",
    "print(train_outputs.shape, test_outputs.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_V5GF1n6gw6V",
    "outputId": "6b1af8ec-9c01-4644-de20-14b86f84a3ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         3936\n",
       "unique        3936\n",
       "top       Ag(AuS)2\n",
       "freq             1\n",
       "Name: composition, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ldpId5_gaNO",
    "outputId": "70168c23-bb5b-486a-8659-0e255f68f0d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3936\n",
       "unique        2\n",
       "top       False\n",
       "freq       1976\n",
       "Name: is_metal, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "bj2GVnAmgoz2",
    "outputId": "734cbf72-cf59-4a40-fab9-a195f499e3c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0205870f-7206-490c-adab-8ca7336460cb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-0001</th>\n",
       "      <td>Ag(AuS)2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-0002</th>\n",
       "      <td>Ag(W3Br7)2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-0003</th>\n",
       "      <td>Ag0.5Ge1Pb1.75S4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-0005</th>\n",
       "      <td>Ag2BBr</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-0006</th>\n",
       "      <td>Ag2BiO3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-4916</th>\n",
       "      <td>ZrSiTe</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-4917</th>\n",
       "      <td>ZrTaN3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-4918</th>\n",
       "      <td>ZrTe</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-4920</th>\n",
       "      <td>ZrTiF6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb-expt-is-metal-4921</th>\n",
       "      <td>ZrW2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3936 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0205870f-7206-490c-adab-8ca7336460cb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0205870f-7206-490c-adab-8ca7336460cb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0205870f-7206-490c-adab-8ca7336460cb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                formula  target\n",
       "mbid                                           \n",
       "mb-expt-is-metal-0001          Ag(AuS)2    True\n",
       "mb-expt-is-metal-0002        Ag(W3Br7)2    True\n",
       "mb-expt-is-metal-0003  Ag0.5Ge1Pb1.75S4   False\n",
       "mb-expt-is-metal-0005            Ag2BBr    True\n",
       "mb-expt-is-metal-0006           Ag2BiO3    True\n",
       "...                                 ...     ...\n",
       "mb-expt-is-metal-4916            ZrSiTe    True\n",
       "mb-expt-is-metal-4917            ZrTaN3   False\n",
       "mb-expt-is-metal-4918              ZrTe    True\n",
       "mb-expt-is-metal-4920            ZrTiF6    True\n",
       "mb-expt-is-metal-4921              ZrW2    True\n",
       "\n",
       "[3936 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({\"formula\": train_inputs, \"target\": train_outputs})\n",
    "test_df = pd.DataFrame({\"formula\": test_inputs, \"target\": test_outputs})\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "8K6r-swAhGq9",
    "outputId": "70576fe3-018c-410c-a5e2-d75dfc319910"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 3936/3936 [00:00<00:00, 15165.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 3936/3936 [00:00<00:00, 8136.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d37b331d-cba9-4354-a54e-2aa92c52f0f6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_Atomic_Number</th>\n",
       "      <th>avg_Atomic_Weight</th>\n",
       "      <th>avg_Period</th>\n",
       "      <th>avg_group</th>\n",
       "      <th>avg_families</th>\n",
       "      <th>avg_Metal</th>\n",
       "      <th>avg_Nonmetal</th>\n",
       "      <th>avg_Metalliod</th>\n",
       "      <th>avg_Mendeleev_Number</th>\n",
       "      <th>avg_l_quantum_number</th>\n",
       "      <th>avg_Atomic_Radius</th>\n",
       "      <th>avg_Miracle_Radius_[pm]</th>\n",
       "      <th>avg_Covalent_Radius</th>\n",
       "      <th>avg_Zunger_radii_sum</th>\n",
       "      <th>avg_ionic_radius</th>\n",
       "      <th>avg_crystal_radius</th>\n",
       "      <th>avg_Pauling_Electronegativity</th>\n",
       "      <th>avg_MB_electonegativity</th>\n",
       "      <th>avg_Gordy_electonegativity</th>\n",
       "      <th>avg_Mulliken_EN</th>\n",
       "      <th>avg_Allred-Rockow_electronegativity</th>\n",
       "      <th>avg_metallic_valence</th>\n",
       "      <th>avg_number_of_valence_electrons</th>\n",
       "      <th>avg_gilmor_number_of_valence_electron</th>\n",
       "      <th>avg_valence_s</th>\n",
       "      <th>avg_valence_p</th>\n",
       "      <th>avg_valence_d</th>\n",
       "      <th>avg_valence_f</th>\n",
       "      <th>avg_Number_of_unfilled_s_valence_electrons</th>\n",
       "      <th>avg_Number_of_unfilled_p_valence_electrons</th>\n",
       "      <th>avg_Number_of_unfilled_d_valence_electrons</th>\n",
       "      <th>avg_Number_of_unfilled_f_valence_electrons</th>\n",
       "      <th>avg_outer_shell_electrons</th>\n",
       "      <th>avg_1st_ionization_potential_(kJ/mol)</th>\n",
       "      <th>avg_polarizability(A^3)</th>\n",
       "      <th>avg_Melting_point_(K)</th>\n",
       "      <th>avg_Boiling_Point_(K)</th>\n",
       "      <th>avg_Density_(g/mL)</th>\n",
       "      <th>avg_specific_heat_(J/g_K)_</th>\n",
       "      <th>avg_heat_of_fusion_(kJ/mol)_</th>\n",
       "      <th>...</th>\n",
       "      <th>mode_families</th>\n",
       "      <th>mode_Metal</th>\n",
       "      <th>mode_Nonmetal</th>\n",
       "      <th>mode_Metalliod</th>\n",
       "      <th>mode_Mendeleev_Number</th>\n",
       "      <th>mode_l_quantum_number</th>\n",
       "      <th>mode_Atomic_Radius</th>\n",
       "      <th>mode_Miracle_Radius_[pm]</th>\n",
       "      <th>mode_Covalent_Radius</th>\n",
       "      <th>mode_Zunger_radii_sum</th>\n",
       "      <th>mode_ionic_radius</th>\n",
       "      <th>mode_crystal_radius</th>\n",
       "      <th>mode_Pauling_Electronegativity</th>\n",
       "      <th>mode_MB_electonegativity</th>\n",
       "      <th>mode_Gordy_electonegativity</th>\n",
       "      <th>mode_Mulliken_EN</th>\n",
       "      <th>mode_Allred-Rockow_electronegativity</th>\n",
       "      <th>mode_metallic_valence</th>\n",
       "      <th>mode_number_of_valence_electrons</th>\n",
       "      <th>mode_gilmor_number_of_valence_electron</th>\n",
       "      <th>mode_valence_s</th>\n",
       "      <th>mode_valence_p</th>\n",
       "      <th>mode_valence_d</th>\n",
       "      <th>mode_valence_f</th>\n",
       "      <th>mode_Number_of_unfilled_s_valence_electrons</th>\n",
       "      <th>mode_Number_of_unfilled_p_valence_electrons</th>\n",
       "      <th>mode_Number_of_unfilled_d_valence_electrons</th>\n",
       "      <th>mode_Number_of_unfilled_f_valence_electrons</th>\n",
       "      <th>mode_outer_shell_electrons</th>\n",
       "      <th>mode_1st_ionization_potential_(kJ/mol)</th>\n",
       "      <th>mode_polarizability(A^3)</th>\n",
       "      <th>mode_Melting_point_(K)</th>\n",
       "      <th>mode_Boiling_Point_(K)</th>\n",
       "      <th>mode_Density_(g/mL)</th>\n",
       "      <th>mode_specific_heat_(J/g_K)_</th>\n",
       "      <th>mode_heat_of_fusion_(kJ/mol)_</th>\n",
       "      <th>mode_heat_of_vaporization_(kJ/mol)_</th>\n",
       "      <th>mode_thermal_conductivity_(W/(m_K))_</th>\n",
       "      <th>mode_heat_atomization(kJ/mol)</th>\n",
       "      <th>mode_Cohesive_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.400000</td>\n",
       "      <td>113.186656</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.378000</td>\n",
       "      <td>127.200000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>1.979000</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>1.034000</td>\n",
       "      <td>2.434000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>6.300400</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2.177600</td>\n",
       "      <td>4.064000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>902.200000</td>\n",
       "      <td>5.180000</td>\n",
       "      <td>936.270000</td>\n",
       "      <td>2125.430000</td>\n",
       "      <td>10.648000</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>7.967000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5.8458</td>\n",
       "      <td>5.77</td>\n",
       "      <td>1.920</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>2.900</td>\n",
       "      <td>385.95</td>\n",
       "      <td>717.85</td>\n",
       "      <td>2.07000</td>\n",
       "      <td>0.128</td>\n",
       "      <td>1.71750</td>\n",
       "      <td>9.8000</td>\n",
       "      <td>0.26900</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.714286</td>\n",
       "      <td>110.931629</td>\n",
       "      <td>4.619048</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>1.256667</td>\n",
       "      <td>133.242647</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.694524</td>\n",
       "      <td>1.228571</td>\n",
       "      <td>1.486190</td>\n",
       "      <td>2.739524</td>\n",
       "      <td>2.449048</td>\n",
       "      <td>6.393686</td>\n",
       "      <td>6.528571</td>\n",
       "      <td>2.299048</td>\n",
       "      <td>1.910476</td>\n",
       "      <td>6.904762</td>\n",
       "      <td>5.904762</td>\n",
       "      <td>1.952381</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.380952</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>1014.809524</td>\n",
       "      <td>5.614286</td>\n",
       "      <td>1288.445238</td>\n",
       "      <td>2034.826190</td>\n",
       "      <td>8.094286</td>\n",
       "      <td>0.363667</td>\n",
       "      <td>14.176381</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.83</td>\n",
       "      <td>6.4079</td>\n",
       "      <td>7.59</td>\n",
       "      <td>2.685</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>3.100</td>\n",
       "      <td>265.95</td>\n",
       "      <td>331.95</td>\n",
       "      <td>3.12000</td>\n",
       "      <td>0.473</td>\n",
       "      <td>5.28600</td>\n",
       "      <td>15.4380</td>\n",
       "      <td>0.12200</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.275862</td>\n",
       "      <td>85.159738</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.896552</td>\n",
       "      <td>6.172414</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>83.482759</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.143448</td>\n",
       "      <td>124.482759</td>\n",
       "      <td>1.191379</td>\n",
       "      <td>1.490345</td>\n",
       "      <td>1.268966</td>\n",
       "      <td>0.758966</td>\n",
       "      <td>2.285172</td>\n",
       "      <td>2.273793</td>\n",
       "      <td>5.275255</td>\n",
       "      <td>5.313793</td>\n",
       "      <td>2.279931</td>\n",
       "      <td>2.619310</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>4.965517</td>\n",
       "      <td>1.931034</td>\n",
       "      <td>2.965517</td>\n",
       "      <td>3.103448</td>\n",
       "      <td>3.379310</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>3.034483</td>\n",
       "      <td>6.896552</td>\n",
       "      <td>10.620690</td>\n",
       "      <td>4.896552</td>\n",
       "      <td>880.068966</td>\n",
       "      <td>4.627586</td>\n",
       "      <td>611.456897</td>\n",
       "      <td>1481.398276</td>\n",
       "      <td>5.351724</td>\n",
       "      <td>0.483448</td>\n",
       "      <td>7.980448</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.65</td>\n",
       "      <td>5.8458</td>\n",
       "      <td>6.22</td>\n",
       "      <td>2.589</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.900</td>\n",
       "      <td>385.95</td>\n",
       "      <td>717.85</td>\n",
       "      <td>2.07000</td>\n",
       "      <td>0.710</td>\n",
       "      <td>1.71750</td>\n",
       "      <td>9.8000</td>\n",
       "      <td>0.26900</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.500000</td>\n",
       "      <td>76.612850</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>74.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.277500</td>\n",
       "      <td>133.242647</td>\n",
       "      <td>1.255000</td>\n",
       "      <td>1.686250</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>2.215000</td>\n",
       "      <td>1.717500</td>\n",
       "      <td>4.676850</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>2.119000</td>\n",
       "      <td>3.470000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>850.750000</td>\n",
       "      <td>5.475000</td>\n",
       "      <td>1272.100000</td>\n",
       "      <td>2394.312500</td>\n",
       "      <td>6.615000</td>\n",
       "      <td>0.490750</td>\n",
       "      <td>19.521500</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.07</td>\n",
       "      <td>3.8522</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.870</td>\n",
       "      <td>5.44</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>7.900</td>\n",
       "      <td>1235.15</td>\n",
       "      <td>2485.15</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>0.235</td>\n",
       "      <td>11.30000</td>\n",
       "      <td>250.5800</td>\n",
       "      <td>429.00000</td>\n",
       "      <td>284.0</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.500000</td>\n",
       "      <td>78.785828</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.028333</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.118333</td>\n",
       "      <td>1.357000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.373333</td>\n",
       "      <td>6.274017</td>\n",
       "      <td>6.031667</td>\n",
       "      <td>2.763333</td>\n",
       "      <td>2.313333</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>1017.833333</td>\n",
       "      <td>4.263167</td>\n",
       "      <td>529.783333</td>\n",
       "      <td>1178.983333</td>\n",
       "      <td>5.125715</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>5.761295</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.21</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.32</td>\n",
       "      <td>8.3703</td>\n",
       "      <td>7.54</td>\n",
       "      <td>3.610</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.793</td>\n",
       "      <td>54.75</td>\n",
       "      <td>90.15</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.22259</td>\n",
       "      <td>3.4099</td>\n",
       "      <td>0.02674</td>\n",
       "      <td>249.0</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>35.333333</td>\n",
       "      <td>82.303167</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>1.313333</td>\n",
       "      <td>1.971667</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>1.776667</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>4.359700</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1.798000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>765.333333</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>1510.316667</td>\n",
       "      <td>2847.083333</td>\n",
       "      <td>5.026667</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>28.313333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.420</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.4521</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.320</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>5.400</td>\n",
       "      <td>722.65</td>\n",
       "      <td>1262.95</td>\n",
       "      <td>2.33000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>16.90000</td>\n",
       "      <td>52.5500</td>\n",
       "      <td>2.35000</td>\n",
       "      <td>197.0</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>26.800000</td>\n",
       "      <td>62.838424</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.148000</td>\n",
       "      <td>103.800000</td>\n",
       "      <td>1.022000</td>\n",
       "      <td>1.447000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>2.438000</td>\n",
       "      <td>6.135220</td>\n",
       "      <td>5.930000</td>\n",
       "      <td>2.371600</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1121.400000</td>\n",
       "      <td>6.860000</td>\n",
       "      <td>1116.810000</td>\n",
       "      <td>2116.070000</td>\n",
       "      <td>4.622750</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>9.916240</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.85</td>\n",
       "      <td>6.8834</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.066</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>1.100</td>\n",
       "      <td>63.25</td>\n",
       "      <td>77.35</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.36040</td>\n",
       "      <td>2.7928</td>\n",
       "      <td>0.02598</td>\n",
       "      <td>473.0</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>109.412000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.645000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.415000</td>\n",
       "      <td>2.247500</td>\n",
       "      <td>1.475000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>1.715000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>4.446950</td>\n",
       "      <td>4.565000</td>\n",
       "      <td>1.739000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>754.500000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>1423.900000</td>\n",
       "      <td>2956.550000</td>\n",
       "      <td>6.375000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>17.195000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.670</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.4521</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.320</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>5.500</td>\n",
       "      <td>722.65</td>\n",
       "      <td>1262.95</td>\n",
       "      <td>6.24000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>16.90000</td>\n",
       "      <td>52.5500</td>\n",
       "      <td>2.35000</td>\n",
       "      <td>197.0</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>14.500000</td>\n",
       "      <td>31.636802</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.625000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>133.242647</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.979375</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>3.343750</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>8.387550</td>\n",
       "      <td>8.693750</td>\n",
       "      <td>3.482250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1423.125000</td>\n",
       "      <td>4.538000</td>\n",
       "      <td>547.300000</td>\n",
       "      <td>1090.075000</td>\n",
       "      <td>1.382525</td>\n",
       "      <td>0.713750</td>\n",
       "      <td>4.235150</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.19</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.78</td>\n",
       "      <td>10.0854</td>\n",
       "      <td>10.41</td>\n",
       "      <td>4.193</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>53.35</td>\n",
       "      <td>85.05</td>\n",
       "      <td>0.00170</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.25520</td>\n",
       "      <td>3.2698</td>\n",
       "      <td>0.02790</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>62.666667</td>\n",
       "      <td>152.968000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.973333</td>\n",
       "      <td>142.666667</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>2.765000</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>2.016667</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>5.673433</td>\n",
       "      <td>4.146667</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>5.186667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>726.666667</td>\n",
       "      <td>13.366667</td>\n",
       "      <td>3163.816667</td>\n",
       "      <td>5505.483333</td>\n",
       "      <td>15.036667</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>29.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.735</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1.79</td>\n",
       "      <td>6.7841</td>\n",
       "      <td>4.40</td>\n",
       "      <td>1.470</td>\n",
       "      <td>5.78</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>11.100</td>\n",
       "      <td>3683.15</td>\n",
       "      <td>5933.15</td>\n",
       "      <td>19.30000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>35.40000</td>\n",
       "      <td>824.0000</td>\n",
       "      <td>174.00000</td>\n",
       "      <td>849.0</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3936 rows × 264 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d37b331d-cba9-4354-a54e-2aa92c52f0f6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d37b331d-cba9-4354-a54e-2aa92c52f0f6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d37b331d-cba9-4354-a54e-2aa92c52f0f6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      avg_Atomic_Number  ...  mode_Cohesive_energy\n",
       "0             47.400000  ...                  2.85\n",
       "1             46.714286  ...                  1.22\n",
       "2             36.275862  ...                  2.85\n",
       "3             33.500000  ...                  2.95\n",
       "4             33.500000  ...                  2.62\n",
       "...                 ...  ...                   ...\n",
       "3931          35.333333  ...                  2.19\n",
       "3932          26.800000  ...                  4.92\n",
       "3933          46.000000  ...                  2.19\n",
       "3934          14.500000  ...                  0.84\n",
       "3935          62.666667  ...                  8.90\n",
       "\n",
       "[3936 rows x 264 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, _, _ = generate_features(train_df)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "9_RtynXIhL2e",
    "outputId": "55a2d218-54ed-4fe9-ef73-7a9fc5a9ea38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 985/985 [00:00<00:00, 15770.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 985/985 [00:00<00:00, 7830.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-47df7bdd-c8f9-4c54-8da3-864c081af92c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_Atomic_Number</th>\n",
       "      <th>avg_Atomic_Weight</th>\n",
       "      <th>avg_Period</th>\n",
       "      <th>avg_group</th>\n",
       "      <th>avg_families</th>\n",
       "      <th>avg_Metal</th>\n",
       "      <th>avg_Nonmetal</th>\n",
       "      <th>avg_Metalliod</th>\n",
       "      <th>avg_Mendeleev_Number</th>\n",
       "      <th>avg_l_quantum_number</th>\n",
       "      <th>avg_Atomic_Radius</th>\n",
       "      <th>avg_Miracle_Radius_[pm]</th>\n",
       "      <th>avg_Covalent_Radius</th>\n",
       "      <th>avg_Zunger_radii_sum</th>\n",
       "      <th>avg_ionic_radius</th>\n",
       "      <th>avg_crystal_radius</th>\n",
       "      <th>avg_Pauling_Electronegativity</th>\n",
       "      <th>avg_MB_electonegativity</th>\n",
       "      <th>avg_Gordy_electonegativity</th>\n",
       "      <th>avg_Mulliken_EN</th>\n",
       "      <th>avg_Allred-Rockow_electronegativity</th>\n",
       "      <th>avg_metallic_valence</th>\n",
       "      <th>avg_number_of_valence_electrons</th>\n",
       "      <th>avg_gilmor_number_of_valence_electron</th>\n",
       "      <th>avg_valence_s</th>\n",
       "      <th>avg_valence_p</th>\n",
       "      <th>avg_valence_d</th>\n",
       "      <th>avg_valence_f</th>\n",
       "      <th>avg_Number_of_unfilled_s_valence_electrons</th>\n",
       "      <th>avg_Number_of_unfilled_p_valence_electrons</th>\n",
       "      <th>avg_Number_of_unfilled_d_valence_electrons</th>\n",
       "      <th>avg_Number_of_unfilled_f_valence_electrons</th>\n",
       "      <th>avg_outer_shell_electrons</th>\n",
       "      <th>avg_1st_ionization_potential_(kJ/mol)</th>\n",
       "      <th>avg_polarizability(A^3)</th>\n",
       "      <th>avg_Melting_point_(K)</th>\n",
       "      <th>avg_Boiling_Point_(K)</th>\n",
       "      <th>avg_Density_(g/mL)</th>\n",
       "      <th>avg_specific_heat_(J/g_K)_</th>\n",
       "      <th>avg_heat_of_fusion_(kJ/mol)_</th>\n",
       "      <th>...</th>\n",
       "      <th>mode_families</th>\n",
       "      <th>mode_Metal</th>\n",
       "      <th>mode_Nonmetal</th>\n",
       "      <th>mode_Metalliod</th>\n",
       "      <th>mode_Mendeleev_Number</th>\n",
       "      <th>mode_l_quantum_number</th>\n",
       "      <th>mode_Atomic_Radius</th>\n",
       "      <th>mode_Miracle_Radius_[pm]</th>\n",
       "      <th>mode_Covalent_Radius</th>\n",
       "      <th>mode_Zunger_radii_sum</th>\n",
       "      <th>mode_ionic_radius</th>\n",
       "      <th>mode_crystal_radius</th>\n",
       "      <th>mode_Pauling_Electronegativity</th>\n",
       "      <th>mode_MB_electonegativity</th>\n",
       "      <th>mode_Gordy_electonegativity</th>\n",
       "      <th>mode_Mulliken_EN</th>\n",
       "      <th>mode_Allred-Rockow_electronegativity</th>\n",
       "      <th>mode_metallic_valence</th>\n",
       "      <th>mode_number_of_valence_electrons</th>\n",
       "      <th>mode_gilmor_number_of_valence_electron</th>\n",
       "      <th>mode_valence_s</th>\n",
       "      <th>mode_valence_p</th>\n",
       "      <th>mode_valence_d</th>\n",
       "      <th>mode_valence_f</th>\n",
       "      <th>mode_Number_of_unfilled_s_valence_electrons</th>\n",
       "      <th>mode_Number_of_unfilled_p_valence_electrons</th>\n",
       "      <th>mode_Number_of_unfilled_d_valence_electrons</th>\n",
       "      <th>mode_Number_of_unfilled_f_valence_electrons</th>\n",
       "      <th>mode_outer_shell_electrons</th>\n",
       "      <th>mode_1st_ionization_potential_(kJ/mol)</th>\n",
       "      <th>mode_polarizability(A^3)</th>\n",
       "      <th>mode_Melting_point_(K)</th>\n",
       "      <th>mode_Boiling_Point_(K)</th>\n",
       "      <th>mode_Density_(g/mL)</th>\n",
       "      <th>mode_specific_heat_(J/g_K)_</th>\n",
       "      <th>mode_heat_of_fusion_(kJ/mol)_</th>\n",
       "      <th>mode_heat_of_vaporization_(kJ/mol)_</th>\n",
       "      <th>mode_thermal_conductivity_(W/(m_K))_</th>\n",
       "      <th>mode_heat_atomization(kJ/mol)</th>\n",
       "      <th>mode_Cohesive_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.206897</td>\n",
       "      <td>111.032290</td>\n",
       "      <td>4.551724</td>\n",
       "      <td>14.896552</td>\n",
       "      <td>6.172414</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>84.034483</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.226207</td>\n",
       "      <td>132.758621</td>\n",
       "      <td>1.268621</td>\n",
       "      <td>1.592414</td>\n",
       "      <td>1.351724</td>\n",
       "      <td>0.830690</td>\n",
       "      <td>2.268621</td>\n",
       "      <td>2.213103</td>\n",
       "      <td>5.228469</td>\n",
       "      <td>5.131724</td>\n",
       "      <td>2.194414</td>\n",
       "      <td>2.619310</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>4.965517</td>\n",
       "      <td>1.931034</td>\n",
       "      <td>2.965517</td>\n",
       "      <td>3.103448</td>\n",
       "      <td>3.37931</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>3.034483</td>\n",
       "      <td>6.896552</td>\n",
       "      <td>10.62069</td>\n",
       "      <td>4.896552</td>\n",
       "      <td>847.517241</td>\n",
       "      <td>5.124138</td>\n",
       "      <td>668.946552</td>\n",
       "      <td>1613.977586</td>\n",
       "      <td>6.852414</td>\n",
       "      <td>0.268276</td>\n",
       "      <td>10.726103</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.285</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.54</td>\n",
       "      <td>5.7610</td>\n",
       "      <td>5.89</td>\n",
       "      <td>2.434</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>3.800</td>\n",
       "      <td>490.15</td>\n",
       "      <td>958.15</td>\n",
       "      <td>4.79000</td>\n",
       "      <td>0.320</td>\n",
       "      <td>6.69400</td>\n",
       "      <td>37.7000</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.750000</td>\n",
       "      <td>57.815474</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>78.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.001250</td>\n",
       "      <td>100.375000</td>\n",
       "      <td>1.087500</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.043750</td>\n",
       "      <td>1.178750</td>\n",
       "      <td>2.716250</td>\n",
       "      <td>2.345000</td>\n",
       "      <td>6.276225</td>\n",
       "      <td>6.097500</td>\n",
       "      <td>2.782625</td>\n",
       "      <td>2.415000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1049.500000</td>\n",
       "      <td>3.896500</td>\n",
       "      <td>626.825000</td>\n",
       "      <td>1088.275000</td>\n",
       "      <td>4.654465</td>\n",
       "      <td>0.589375</td>\n",
       "      <td>7.811295</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.21</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.32</td>\n",
       "      <td>8.3703</td>\n",
       "      <td>7.54</td>\n",
       "      <td>3.610</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.793</td>\n",
       "      <td>54.75</td>\n",
       "      <td>90.15</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.22259</td>\n",
       "      <td>3.4099</td>\n",
       "      <td>0.02674</td>\n",
       "      <td>249.0</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.750000</td>\n",
       "      <td>107.506150</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>1.475000</td>\n",
       "      <td>2.393750</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.997500</td>\n",
       "      <td>1.322500</td>\n",
       "      <td>3.836150</td>\n",
       "      <td>4.442500</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>5.525000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>749.250000</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>1383.150000</td>\n",
       "      <td>2717.150000</td>\n",
       "      <td>10.875000</td>\n",
       "      <td>0.236250</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.07</td>\n",
       "      <td>3.8522</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.870</td>\n",
       "      <td>5.44</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>7.900</td>\n",
       "      <td>1235.15</td>\n",
       "      <td>2485.15</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>0.235</td>\n",
       "      <td>11.30000</td>\n",
       "      <td>250.5800</td>\n",
       "      <td>429.00000</td>\n",
       "      <td>284.0</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.125000</td>\n",
       "      <td>61.084025</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>13.125000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.081250</td>\n",
       "      <td>102.750000</td>\n",
       "      <td>1.096250</td>\n",
       "      <td>1.448750</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.191250</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>2.307500</td>\n",
       "      <td>6.088075</td>\n",
       "      <td>5.997500</td>\n",
       "      <td>2.698750</td>\n",
       "      <td>2.762500</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1019.875000</td>\n",
       "      <td>4.559000</td>\n",
       "      <td>813.450000</td>\n",
       "      <td>1498.650000</td>\n",
       "      <td>5.488215</td>\n",
       "      <td>0.577875</td>\n",
       "      <td>7.348795</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.21</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.32</td>\n",
       "      <td>8.3703</td>\n",
       "      <td>7.54</td>\n",
       "      <td>3.610</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>0.793</td>\n",
       "      <td>54.75</td>\n",
       "      <td>90.15</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.22259</td>\n",
       "      <td>3.4099</td>\n",
       "      <td>0.02674</td>\n",
       "      <td>249.0</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.454545</td>\n",
       "      <td>97.547122</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.818182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.419091</td>\n",
       "      <td>133.403704</td>\n",
       "      <td>1.400909</td>\n",
       "      <td>1.999545</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>1.273636</td>\n",
       "      <td>2.180909</td>\n",
       "      <td>1.664545</td>\n",
       "      <td>4.592800</td>\n",
       "      <td>5.185455</td>\n",
       "      <td>2.089636</td>\n",
       "      <td>3.825455</td>\n",
       "      <td>9.363636</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>830.272727</td>\n",
       "      <td>6.463636</td>\n",
       "      <td>926.477273</td>\n",
       "      <td>1795.095455</td>\n",
       "      <td>7.954545</td>\n",
       "      <td>0.317545</td>\n",
       "      <td>8.925727</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.07</td>\n",
       "      <td>3.8522</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.870</td>\n",
       "      <td>5.44</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>7.900</td>\n",
       "      <td>1235.15</td>\n",
       "      <td>2485.15</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>0.235</td>\n",
       "      <td>11.30000</td>\n",
       "      <td>250.5800</td>\n",
       "      <td>429.00000</td>\n",
       "      <td>284.0</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>51.785333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.273333</td>\n",
       "      <td>121.333333</td>\n",
       "      <td>1.173333</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>2.163333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.047900</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>2.166000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>965.683333</td>\n",
       "      <td>2028.616667</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>6.778333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.65</td>\n",
       "      <td>5.8458</td>\n",
       "      <td>6.22</td>\n",
       "      <td>2.589</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.900</td>\n",
       "      <td>385.95</td>\n",
       "      <td>717.85</td>\n",
       "      <td>2.07000</td>\n",
       "      <td>0.710</td>\n",
       "      <td>1.71750</td>\n",
       "      <td>9.8000</td>\n",
       "      <td>0.26900</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>104.684667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.723333</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.373333</td>\n",
       "      <td>2.398333</td>\n",
       "      <td>1.433333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>1.936667</td>\n",
       "      <td>4.038067</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>1.614667</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>11.366667</td>\n",
       "      <td>1870.816667</td>\n",
       "      <td>3682.150000</td>\n",
       "      <td>8.533333</td>\n",
       "      <td>0.239333</td>\n",
       "      <td>20.256667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.765</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.4521</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.320</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>6.600</td>\n",
       "      <td>904.15</td>\n",
       "      <td>2223.15</td>\n",
       "      <td>6.51000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>16.90000</td>\n",
       "      <td>77.1400</td>\n",
       "      <td>22.70000</td>\n",
       "      <td>262.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>85.092000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>4.606550</td>\n",
       "      <td>4.765000</td>\n",
       "      <td>1.877000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>790.500000</td>\n",
       "      <td>10.850000</td>\n",
       "      <td>1307.650000</td>\n",
       "      <td>2804.150000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>11.797000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.285</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.4521</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.320</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.800</td>\n",
       "      <td>490.15</td>\n",
       "      <td>958.15</td>\n",
       "      <td>4.79000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>6.69400</td>\n",
       "      <td>37.7000</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>22.666667</td>\n",
       "      <td>49.131667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.426667</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1.888333</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>1.886667</td>\n",
       "      <td>3.940833</td>\n",
       "      <td>4.393333</td>\n",
       "      <td>1.717333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>9.566667</td>\n",
       "      <td>1830.483333</td>\n",
       "      <td>3302.150000</td>\n",
       "      <td>3.723333</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.420</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.1852</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.916</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>5.400</td>\n",
       "      <td>1683.15</td>\n",
       "      <td>2628.15</td>\n",
       "      <td>2.33000</td>\n",
       "      <td>0.710</td>\n",
       "      <td>50.55000</td>\n",
       "      <td>384.2200</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>452.0</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>50.745850</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.515000</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>1.232500</td>\n",
       "      <td>2.112500</td>\n",
       "      <td>1.237500</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>1.962500</td>\n",
       "      <td>2.185000</td>\n",
       "      <td>4.523550</td>\n",
       "      <td>4.520000</td>\n",
       "      <td>1.922500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>818.000000</td>\n",
       "      <td>11.973250</td>\n",
       "      <td>1511.550000</td>\n",
       "      <td>2965.150000</td>\n",
       "      <td>3.897857</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>12.005647</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.580</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.86</td>\n",
       "      <td>3.1359</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.380</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>14.600</td>\n",
       "      <td>1933.15</td>\n",
       "      <td>3560.15</td>\n",
       "      <td>4.54000</td>\n",
       "      <td>0.520</td>\n",
       "      <td>15.45000</td>\n",
       "      <td>421.0000</td>\n",
       "      <td>21.90000</td>\n",
       "      <td>470.0</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 264 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47df7bdd-c8f9-4c54-8da3-864c081af92c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-47df7bdd-c8f9-4c54-8da3-864c081af92c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-47df7bdd-c8f9-4c54-8da3-864c081af92c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     avg_Atomic_Number  ...  mode_Cohesive_energy\n",
       "0            46.206897  ...                  2.46\n",
       "1            25.750000  ...                  2.62\n",
       "2            46.750000  ...                  2.95\n",
       "3            27.125000  ...                  2.62\n",
       "4            42.454545  ...                  2.95\n",
       "..                 ...  ...                   ...\n",
       "980          24.000000  ...                  2.85\n",
       "981          45.000000  ...                  2.75\n",
       "982          37.000000  ...                  2.46\n",
       "983          22.666667  ...                  4.63\n",
       "984          23.000000  ...                  4.85\n",
       "\n",
       "[985 rows x 264 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test, _, _ = generate_features(test_df)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuEoRyF_iRsV"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq79CBx_iVnl"
   },
   "source": [
    "We can do hyperparameter tuning in different ways. Two common ways are grid search (less efficient) and random search (more efficient). Below are examples taken/modified from the website https://www.geeksforgeeks.org/hyperparameter-tuning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DpTTU0FV8vI",
    "outputId": "1157a51d-ba66-42aa-a173-71329c8df3b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid tuned Logistic Regression Parameters: {'C': 19306.977288832535}\n",
      "Best score is 0.8191010003934494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#Grid search first using logistic regression classifier model\n",
    "\n",
    "# Creating the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "  \n",
    "# Instantiating logistic regression classifier\n",
    "# https://stats.stackexchange.com/a/184026/293880\n",
    "logreg = LogisticRegression(max_iter=100)\n",
    "  \n",
    "# Instantiating the GridSearchCV object\n",
    "logreg_grid = GridSearchCV(logreg, param_grid, cv = 5)\n",
    "  \n",
    "logreg_grid.fit(X_train, y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "print(\"Grid tuned Logistic Regression Parameters: {}\".format(logreg_grid.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtZMtOBiV8vJ",
    "outputId": "1e27eb3b-6675-4a83-8f44-332994b4eba9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tuned Logistic Regression Parameters: {'C': 3}\n",
      "Best score is 0.820117841317346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#Now we can try random search with logistic regression\n",
    "  \n",
    "# Creating the hyperparameter grid \n",
    "param_dist = {\"C\": randint(-5,15)}\n",
    "  \n",
    "# Instantiating Decision Tree classifier\n",
    "logreg = LogisticRegression()\n",
    "  \n",
    "# Instantiating RandomizedSearchCV object\n",
    "logreg_random = RandomizedSearchCV(logreg, param_dist, cv = 5)\n",
    "  \n",
    "logreg_random.fit(X_train, y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "print(\"Random tuned Logistic Regression Parameters: {}\".format(logreg_random.best_params_))\n",
    "print(\"Best score is {}\".format(logreg_random.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0jdvkp_V8vJ"
   },
   "source": [
    "We can do the same grid vs random search with another model, like a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lwxtaSddV8vJ",
    "outputId": "5a4832af-c902-4d12-a67a-eb50f9e31648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 6, 'max_features': 7, 'min_samples_leaf': 5}\n",
      "Best score is 0.850099652345539\n"
     ]
    }
   ],
   "source": [
    "#grid search for decision tree hyperparameters\n",
    "  \n",
    "# Creating the hyperparameter grid \n",
    "param_grid = {\"max_depth\": range(1,10),\n",
    "              \"max_features\": range(1,10),\n",
    "              \"min_samples_leaf\": range(1,10),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiating Decision Tree classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "  \n",
    "# Instantiating GridSearchCV object\n",
    "tree_grid = GridSearchCV(tree, param_grid, cv = 5)\n",
    "  \n",
    "tree_grid.fit(X_train, y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "print(\"Grid tuned Decision Tree Parameters: {}\".format(tree_grid.best_params_))\n",
    "print(\"Best score is {}\".format(tree_grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdIPhe3WV8vK",
    "outputId": "10490388-2cca-4416-c249-a249e44d161c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 8, 'max_features': 5, 'min_samples_leaf': 6}\n",
      "Best score is 0.8219051335470429\n"
     ]
    }
   ],
   "source": [
    "#random search for decision tree hyperparameters\n",
    "  \n",
    "# Creating the hyperparameter grid \n",
    "param_dist = {\"max_depth\": randint(1,10),\n",
    "              \"max_features\": randint(1,10),\n",
    "              \"min_samples_leaf\": randint(1,10),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiating Decision Tree classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "  \n",
    "# Instantiating RandomizedSearchCV object\n",
    "tree_random = RandomizedSearchCV(tree, param_dist, cv = 5)\n",
    "  \n",
    "tree_random.fit(X_train, y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "print(\"Random tuned Decision Tree Parameters: {}\".format(tree_random.best_params_))\n",
    "print(\"Best score is {}\".format(tree_random.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBXW3O6phXtl"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8yrOCrj7hXY1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgcnmD4FcGUJ"
   },
   "source": [
    "## Code Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OCT4yE_cJgo"
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# X_train"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "materials_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
