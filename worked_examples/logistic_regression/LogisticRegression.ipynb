{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression allows us to make predictions over binary outcomes. For example, you might want to determine whether a material will fail under an applied stress or classify a material as being an insulator or a conductor. We do this by applying a transform to the familiar linear regression formula such that we now model the relationship between our independent variables and the log-odds of our dependent variable.\n",
    "\n",
    "$$p(X) = \\beta_0 + \\beta_1 X$$\n",
    "$$ \\log \\left( \\frac{p(X)}{1 - p(X)} \\right) = \\beta_0 + \\beta_1 X$$\n",
    "$$ p(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1-e^{\\beta_0 + \\beta_1 X}}$$\n",
    "\n",
    "This is known as the logistic function. It takes on an S-shape, which conincides with how we might wish to model the change between two binary outcomes.\n",
    "\n",
    "In this notebook, we will use logistic regression to model and predict failure in both the challenger disaster and a relevant materials classification problem. Please note that many engineering challenges and failures cannot be boiled down to a simple variable and that there are many competing variables at play in such incidents that cannot be easily modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# some settings for making plots\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "plt.style.use(\"ggplot\")\n",
    "palette = [\"#00B0F6\", \"#F8766D\", \"#00BF7D\", \"#A3A500\", \"#E76BF3\"]\n",
    "plt.rc('axes', prop_cycle=(cycler('color', palette)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by reading in the data, cleaning it, and splitting it into training and testing data. In this hypothetical situation, we are placing ourselve in the position of trying to determine if an incident will occur on launch day based on the previous incident data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"challenger_data.csv\")\n",
    "df.columns = ['date', 'temperature', 'damage_incident'] # simplify column names\n",
    "df.dropna(inplace=True) # drop the NAN value\n",
    "\n",
    "df.iloc[-1, -1] = 1 # replace the challenger incident label with a 1\n",
    "df['damage_incident'] = df['damage_incident'].astype(int) # convert indicent to int type\n",
    "\n",
    "df_train = df.iloc[:-1, :].copy() # create a dataset for training the model\n",
    "df_test = pd.DataFrame([df.iloc[-1, :].copy()]) # create a dataset for testing the model\n",
    "\n",
    "# take a look at what our data looks like from a statistical perspective\n",
    "print(\"df_train stats\")\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While numerical statistics are useful, it can be helpful to visualize the data graphically to build some intution for relationships between variables and features that might pose problems. In this example, we only have a single variable, but as we shall see in later examples, things aren't always simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3), dpi=120)\n",
    "plt.scatter(\n",
    "    df_train['temperature'], \n",
    "    df_train['damage_incident'],\n",
    "    color='k',\n",
    "    marker='|')\n",
    "plt.title(\"Challenger Shuttle Incidents\", loc='left')\n",
    "plt.xlabel(\"Temperature (F)\")\n",
    "plt.ylabel(\"Damage Incident\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit a logistic regression model with `statsmodels` by calling `smf.logit` and then filling in the familiar formula syntax. As the relationship is quite simple, we won't consider higher order models for predicting this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit('damage_incident ~ temperature', data=df_train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our transform of the linear relationship is now causing us to model the log odds of the response. Recall as well the interpretation of odds from a statistical stand point:\n",
    "\n",
    "$$ \\log (\\text{odds}) \\quad \\text{where odds} = \\frac{\\text{Probability of Event}}{\\text{Probability of Non-Event}}$$\n",
    "\n",
    "Because we have transformed our model, we need to change our intepretation of our model coefficients. We are modeling the linear relationship between our independent variables and the log-odds of failure. The `Intercept` now provides the log odds of an incident when `temperature=0`, which would suggest that at low temperatures the probability of an incident occuring is highly likely. Looking at the `temperature` coefficient, we see that for a unit increase in temperature the log odds of an incident **decrease** by 0.2322. We can convert this to odds ratio change by exponentiating to get 0.793. This can be understood as a unit temperature change affecting 79.3% decrease in the odds ratio of failure; that is, a 79.3% decrease from the previous odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting our Predictions\n",
    "We can examine our model graphically by using to to predict on temperatures that span the temperature range of interest. In the code below we create some dummy data and use our trained model to predict the probability of an incident with it. In addition to the mean response, we alos include the confidence intervals on our predictions. The inclusion of confidence intervals can give us a measure of uncertinaty in the *true* relationship between our dependent and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some dummy data to predict over\n",
    "temp_data = pd.DataFrame({'temperature':np.linspace(45, 90, 100)})\n",
    "sm.add_constant(temp_data)\n",
    "predictions = model.get_prediction(temp_data)\n",
    "\n",
    "preds = predictions.predicted # get predicted values\n",
    "conf_ints= predictions.conf_int() # get confidence intervals\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,3), dpi=120, layout='tight')\n",
    "plt.scatter(\n",
    "    df_train['temperature'], \n",
    "    df_train['damage_incident'],\n",
    "    color='k',\n",
    "    marker='|',\n",
    "    label='Raw Data')\n",
    "\n",
    "plt.plot(temp_data, preds, lw=2, label=\"Prediction\")\n",
    "plt.fill_between(temp_data.iloc[:,0], conf_ints[:,0], conf_ints[:,1], alpha=0.3, label=\"95% Conf. Int.\")\n",
    "plt.yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "plt.xlabel(\"Temperature (F)\")\n",
    "plt.ylabel(\"Damage Incident\")\n",
    "plt.legend(frameon=False, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to predict the probability of an incident occuring as a function of temperature, but our task isn't finished. Our aim is to be able to provide a definite answer as a function of temperature, which means we need to convert these probabilities into a binary decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Threshold\n",
    "\n",
    "Now that we have our model, we need to define a probability threshold from which we will render a decision. A naive first attempt might be to say that anything above 50% failure probability is a 1 and anything below 50% failure probability is a 0. To assess the impacts of this classification threhsold we can test the accuracy of these predictions and construct a confusion matrix. The confusion matrix gives a better understanding of which classes we are misclassifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(df_train) # predict the training data\n",
    "\n",
    "threshold=0.5 # set a decision threshold\n",
    "\n",
    "train_pred = np.where(train_pred>threshold, 1, 0) # apply the threshold\n",
    "\n",
    "print(\"Prediction Accuracy: \", accuracy_score(df_train['damage_incident'], train_pred))\n",
    "\n",
    "cm = confusion_matrix(df_train['damage_incident'], train_pred)\n",
    "print(\"True Positive \", cm[1,1])\n",
    "print(\"False Negative\", cm[1,0], \"(!)\")\n",
    "print(\"False Positive\", cm[0,1])\n",
    "print(\"True Negative \", cm[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prediction accuracy doesn't seem too bad, but the confusion matrix tells us that our model predicts an incident-free flight incorrectly for three of the datapoints! Under some circumstances, this level of error might be ok, but when human lives are on the line, we may wish to be a bit more conservative with our selection threshold.\n",
    "\n",
    "Deciding an optimal threshold falls into a branch of mathematics called decision theory, for which there is an extensive literature. Depending on the complexity of the response you are attempting to predict, you might have an equally complex decision function that takes into account the uncertainty in that prediction in additional to other potential variables that are computed seperately. Under some circumstances it may be acceptable to have the model say I don't know if there isn't a clear answer and have the problem further analyzed by humans. One should think critically about the impacts of a particular decision to guide the selection of an appropriate threshold. In the case of a multi-billion dollar rocket carrying human souls, a lower threshold that better guarantees survival might be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Failure on Launch Day\n",
    "\n",
    "Now we can test our model on launch day conditions and make a decision as to whether it is safe to proceed with the launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_pred = model.get_prediction(df_test)\n",
    "\n",
    "print(\"Predicted Failure Probability\", launch_pred.predicted[0])\n",
    "print(\"Predicted Failure Probability Bounds\", launch_pred.conf_int()[0])\n",
    "print(f\"Incident Decision: {1 if launch_pred.predicted[0] > 0.2 else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A New Problem with More Variables\n",
    "\n",
    "A company comes to you asking to use a material you made in a machine they are designing. They provide you with some expected environmental conditions and ask you if you material will be able to survive. Thankfully you have data on your material under similar conditions and now know how to build a model to predict failure under new conditions.\n",
    "\n",
    "The company says that their material will be under the following conditions:\n",
    "- temperature: 250,\n",
    "- applied_tensile_stress: 120\n",
    "- humidity: 0.3\n",
    "- corrosive_index: 0.8\n",
    "\n",
    "Using the component_failure dataset, we will build a model to predict whether our material will fail under these conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('component_failure.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the data below to gain some intuition for which predictors might be good in a model and try to understand the data a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 3))\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].set_title(df.columns[i])\n",
    "    ax[i].scatter(df.iloc[:,i], df.fail, color='k', marker='|', alpha=0.5)\n",
    "    ax[i].set_yticks([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first pass, we think that `corrosive_index` might be a good predictor, so we attempt to build a simple model with that predictor and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_var = 'corrosive_index'\n",
    "model = smf.logit(f'fail ~ {pred_var}', data=df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = df[pred_var].sort_values()\n",
    "sm.add_constant(pred_data)\n",
    "predictions = model.get_prediction(pred_data)\n",
    "\n",
    "preds = predictions.predicted\n",
    "conf_int = predictions.conf_int()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,3), dpi=120, layout='tight')\n",
    "plt.scatter(\n",
    "    df[pred_var], \n",
    "    df['fail'],\n",
    "    color='k',\n",
    "    marker='|',\n",
    "    label='Raw Data',\n",
    "    alpha=0.5)\n",
    "\n",
    "plt.plot(pred_data, preds, lw=2, label=\"Prediction\")\n",
    "\n",
    "plt.fill_between(pred_data, conf_int[:,0],conf_int[:,1], alpha=0.3, label=\"95% Conf. Int.\")\n",
    "\n",
    "plt.yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "plt.xlabel(\"Temperature (F)\")\n",
    "plt.ylabel(\"Component Failure\")\n",
    "plt.legend(frameon=False, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single predictor model isn't a great fit, and is show to have weak predictive performance. Looking at the data again, none of the materials immediately stick out as good predictors, but we shouldn't always expect there to be easy relationships! We can try to gain some addition insights by plotting the data in higher dimensions and seeing if we can gain some additional understanding. \n",
    "\n",
    "Below we plot the data in 2D with color coded failure information to see if we can discern a better combination of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=120)\n",
    "plt.scatter(df.temperature, df.corrosive_index, c=df.fail, cmap='coolwarm', edgecolors='k')\n",
    "plt.scatter([],[], color='blue', label='Survive')\n",
    "plt.scatter([],[], color='red', label='Fail')\n",
    "plt.legend(frameon=False, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Temperature\")\n",
    "plt.ylabel(\"Corrosive_Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above seems to suggest that failure is positively correlated with `temperature` and `corrosive_index`, so perhaps an interaction between the two variables would provide a better predictive model. As a materials scientist, I know that reaction rate is related to temperature, so I think a new variables represented by `temperature * corrosive_index` might give me better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit('fail ~ temperature:corrosive_index', data=df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including that an a few other variables has increased our `Pseudo R-squ.` value, indicating a much better fit! For a limited number of predictors we can graphically visualize the model's decision boundary on a 2D plot. We do this below and overlay the training data on it to see how well the model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_range = np.linspace(50, 350, num=100)\n",
    "corrosive_index_range = np.linspace(0, 1, num=50)\n",
    "\n",
    "# Create a grid of points using numpy.meshgrid\n",
    "temperature_grid, corrosive_index_grid = np.meshgrid(temperature_range, corrosive_index_range)\n",
    "\n",
    "# Flatten the grids to create 1D arrays\n",
    "temperature_values = temperature_grid.flatten()\n",
    "corrosive_index_values = corrosive_index_grid.flatten()\n",
    "\n",
    "# Create a DataFrame with the temperature and corrosive index values\n",
    "df_grid = pd.DataFrame({'temperature': temperature_values, 'corrosive_index': corrosive_index_values})\n",
    "\n",
    "pred = model.predict(df_grid)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "plt.scatter(df_grid.temperature, df_grid.corrosive_index, c=pred, cmap='coolwarm', marker='s')\n",
    "plt.scatter(df.temperature, df.corrosive_index, c=df.fail, cmap='coolwarm', edgecolors='w')\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(50,350)\n",
    "plt.xlabel(\"Temperature\")\n",
    "plt.ylabel(\"Corrosive_Index\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the interaction term it looks like we need a more powerful model. We can add additional variables to the model to add some predictive power. We will now add the rest of the variables to the model and see another increase in model accuracy. While we could probably improve the model further, we will call it good enough and try to predict on the companies data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit('fail ~ temperature:corrosive_index + humidity + applied_tensile_stress', data=df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model's accuracy on the training data isn't too bad at the default threshold, despite our weak pseudo r-squ. value we might be ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = df.iloc[:,:-1]\n",
    "pred = model.predict(pred_df)\n",
    "\n",
    "threshold=0.5\n",
    "\n",
    "pred = np.where(pred>threshold, 1, 0)\n",
    "\n",
    "print(\"Prediction Accuracy: \", accuracy_score(df['fail'], pred))\n",
    "\n",
    "cm = confusion_matrix(df['fail'], pred)\n",
    "print(\"True Positive \", cm[1,1])\n",
    "print(\"False Negative\", cm[1,0], \"(!)\")\n",
    "print(\"False Positive\", cm[0,1])\n",
    "print(\"True Negative \", cm[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and make a prediction using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data = pd.DataFrame({\n",
    "    \"temperature\": 250,\n",
    "    'applied_tensile_stress': 120,\n",
    "    'humidity': 0.3,\n",
    "    'corrosive_index': 0.8\n",
    "}, index=[0])\n",
    "\n",
    "client_pred = model.get_prediction(client_data)\n",
    "\n",
    "print(\"Predicted Failure Probability\", client_pred.predicted[0])\n",
    "print(\"Predicted Failure Probability Bounds\", client_pred.conf_int()[0])\n",
    "print(f\"Failure Decision: {1 if client_pred.predicted[0] > 0.5 else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try It Yourself!\n",
    "\n",
    "- Use MPRester to create a list of 3 element oxides containing , or K with their stability and composition\n",
    "- Convert the stability into a binary \n",
    "- Turn the compositions into a CBFV for use with a model (Hint- use sklearn LogisticRegression)\n",
    "- Use this model to predict the stability of NaTa2O4, KNbO3, and LiSb3O2 \n",
    "- If the prediction is above 0.75 then consider the material to be stable otherwise it is unstable. (Key at Bottom)\n",
    "- Helpful docs for sklearn Logistic Regression https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaTa2O4 is predicted as unstable\n",
    "# KNbO3 is predicted as stable\n",
    "# LiSb3O2 is predicted as stable\n",
    "\n",
    "# I used this model with the CBFV data\n",
    "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
    "\n",
    "# I predicted the stability of the following compounds like this\n",
    "y_pred_class = model.predict(df_features)\n",
    "for formula, score in zip(formulae, scores):\n",
    "    print(f\"{formula} is {'stable' if score >0.75 else 'unstable'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MatInformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
