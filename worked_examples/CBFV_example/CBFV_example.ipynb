{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composition Based Feature Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most materials informatics models rely on small amounts of data, we need to rely on feature engineering in order to inject domain knowledge into our materials representations. One of the most simple ways to do so is through the mighty Composition Based Feature Vector.\n",
    "\n",
    "My research group created the `CBFV` package to make it super easy to do composition based feature vectors! In order to follow along with the in class demo (https://github.com/sp8rks/MaterialsInformatics/blob/main/worked_examples/CBFV_example/CBFV_example.ipynb) you will need to go to do the following:\n",
    "(1) open miniconda\n",
    "(2) activate your MatInformatics python env `conda activate MatInformatics`\n",
    "(3) install CBFV package `pip install CBFV` (read more at https://pypi.org/project/CBFV/)\n",
    "\n",
    "Let's start by creating some dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CBFV import composition\n",
    "import pandas as pd\n",
    "\n",
    "data = [['Si1O2', 10], ['Al2O3', 15], ['Hf1C1Zr1', 14]]\n",
    "#this next step is important!! The CBFV composition.generate_features() function \n",
    "#requires an input dataframe with a column named 'formula' and another column named 'target'\n",
    "df = pd.DataFrame(data, columns=['formula', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do our simplest CBFV featurization and convert our data into a 'one hot encoding' vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 3/3 [00:00<00:00, 9131.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 3/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    }
   ],
   "source": [
    "X, y, formulae, skipped = composition.generate_features(df, \n",
    "    elem_prop='onehot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at our input, the X variable, we'll see that the formulae strings are now converted to numerical values that are suitable for machine learning models.\n",
    "\n",
    "For our first representation, the avg columns represent the *fractional encoding* of the elements. For example, SiO2 is 2/3 Oxygen, 1/3 Silicon so we see 0.66667 in the avg_8 (atomic number 8, Oxygen) position and we see 0.33333 in the 14th column (atomic number 14, Silicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_0  avg_1  avg_2  avg_3  avg_4  avg_5     avg_6  avg_7     avg_8  avg_9  \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0  0.666667    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0  0.600000    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0  0.333333    0.0  0.000000    0.0   \n",
      "\n",
      "   ...  mode_109  mode_110  mode_111  mode_112  mode_113  mode_114  mode_115  \\\n",
      "0  ...       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1  ...       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2  ...       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   mode_116  mode_117  mode_118  \n",
      "0       0.0       0.0       0.0  \n",
      "1       0.0       0.0       0.0  \n",
      "2       0.0       0.0       0.0  \n",
      "\n",
      "[3 rows x 714 columns]\n"
     ]
    }
   ],
   "source": [
    "#TIP! Open up the X variable in the Data Wrangler extension to see all the columns since they are truncated below\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Element property feature vectors\n",
    "The one hot encoding is a super simple way to encode the formula. It doesn't include any information about the actual chemistry other than the formula. We know that other features should matter. For example, the melting point or ionic size or number of valence electrons etc should be important and useful in relating these materials to their material properties. \n",
    "\n",
    "Let's take a look at another featurization technique, the `magpie` feature vector, that encodes more chemical information beyond just one hot encoding.\n",
    "\n",
    "Read more about `magpie` here in the original article https://doi.org/10.1038/npjcompumats.2016.28\n",
    "\n",
    "Essentially, the feature vector is created by taking information from the individual elements and then combining the information from these individual elements based on their elemental ratio in the chemical formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 3/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_Number  avg_MendeleevNumber  avg_AtomicWeight  avg_MeltingT  \\\n",
      "0   10.000000            84.000000         20.028100    598.866667   \n",
      "1   10.000000            81.400000         20.392255    406.268000   \n",
      "2   39.333333            55.333333         93.908233   2819.000000   \n",
      "\n",
      "   avg_Column   avg_Row  avg_CovalentRadius  avg_Electronegativity  \\\n",
      "0   15.333333  2.333333                81.0               2.926667   \n",
      "1   14.800000  2.400000                88.0               2.708000   \n",
      "2    7.333333  4.333333               142.0               1.726667   \n",
      "\n",
      "   avg_NsValence  avg_NpValence  ...  mode_NValence  mode_NsUnfilled  \\\n",
      "0            2.0       3.333333  ...            6.0              0.0   \n",
      "1            2.0       2.800000  ...            6.0              0.0   \n",
      "2            2.0       0.666667  ...            4.0              0.0   \n",
      "\n",
      "   mode_NpUnfilled  mode_NdUnfilled  mode_NfUnfilled  mode_NUnfilled  \\\n",
      "0              2.0              0.0              0.0             2.0   \n",
      "1              2.0              0.0              0.0             2.0   \n",
      "2              0.0              0.0              0.0             4.0   \n",
      "\n",
      "   mode_GSvolume_pa  mode_GSbandgap  mode_GSmagmom  mode_SpaceGroupNumber  \n",
      "0             9.105             0.0            0.0                   12.0  \n",
      "1             9.105             0.0            0.0                   12.0  \n",
      "2             5.640             0.0            0.0                  194.0  \n",
      "\n",
      "[3 rows x 132 columns]\n"
     ]
    }
   ],
   "source": [
    "X, y, formulae, skipped = composition.generate_features(df, \n",
    "    elem_prop='magpie')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several others too including one of my favorites `olinyky` which we named after Anton Oliynyk, a great chemist who put it together. https://hunter.cuny.edu/people/anton-oliynyk/ Another is `jarvis` which came from the good folks at NIST. Read their article here https://doi.org/10.1038/s41524-020-00440-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 3/3 [00:00<00:00, 838.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 3/3 [00:00<00:00, 417.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_Atomic_Number  avg_Atomic_Weight  avg_Period  avg_group  avg_families  \\\n",
      "0          10.000000          20.028100    2.333333  15.333333      6.666667   \n",
      "1          10.000000          20.392256    2.400000  14.800000      6.200000   \n",
      "2          39.333333          93.908333    4.333333   7.333333      5.000000   \n",
      "\n",
      "   avg_Metal  avg_Nonmetal  avg_Metalliod  avg_Mendeleev_Number  \\\n",
      "0   0.000000      1.000000            0.0             84.000000   \n",
      "1   0.400000      0.600000            0.0             81.400000   \n",
      "2   0.666667      0.333333            0.0             55.333333   \n",
      "\n",
      "   avg_l_quantum_number  ...  mode_polarizability(A^3)  \\\n",
      "0              1.000000  ...                     0.793   \n",
      "1              1.000000  ...                     0.793   \n",
      "2              1.666667  ...                     1.800   \n",
      "\n",
      "   mode_Melting_point_(K)  mode_Boiling_Point_(K)  mode_Density_(g/mL)  \\\n",
      "0                   54.75                   90.15              0.00143   \n",
      "1                   54.75                   90.15              0.00143   \n",
      "2                 2125.15                 4650.15              2.25000   \n",
      "\n",
      "   mode_specific_heat_(J/g_K)_  mode_heat_of_fusion_(kJ/mol)_  \\\n",
      "0                         0.92                        0.22259   \n",
      "1                         0.92                        0.22259   \n",
      "2                         0.14                       16.90000   \n",
      "\n",
      "   mode_heat_of_vaporization_(kJ/mol)_  mode_thermal_conductivity_(W/(m_K))_  \\\n",
      "0                               3.4099                               0.02674   \n",
      "1                               3.4099                               0.02674   \n",
      "2                             355.8000                              22.70000   \n",
      "\n",
      "   mode_heat_atomization(kJ/mol)  mode_Cohesive_energy  \n",
      "0                          249.0                  2.62  \n",
      "1                          249.0                  2.62  \n",
      "2                          609.0                  6.25  \n",
      "\n",
      "[3 rows x 264 columns]\n"
     ]
    }
   ],
   "source": [
    "X, y, formulae, skipped = composition.generate_features(df, \n",
    "    elem_prop='oliynyk')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization based on scientific literature\n",
    "There are also some really cool approaches for embedding domain knowledge. For example, `mat2vec` is a clever approach that uses a *natural language processing* tool known as word embeddings to create a feature vector based on scientific literature. You can read about it here https://doi.org/10.1038/s41586-019-1335-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 3/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      avg_0     avg_1     avg_2     avg_3     avg_4     avg_5     avg_6  \\\n",
      "0 -0.028195 -0.220953  0.103799  0.036430 -0.180534  0.168473  0.511174   \n",
      "1 -0.051101 -0.165520  0.090990 -0.009840 -0.264100  0.131027  0.490254   \n",
      "2 -0.153709 -0.147015  0.122145 -0.038134 -0.218932  0.098425  0.553805   \n",
      "\n",
      "      avg_7     avg_8     avg_9  ...  mode_190  mode_191  mode_192  mode_193  \\\n",
      "0 -0.038618  0.203725 -0.196661  ...  0.383646 -0.112214 -0.140789 -0.297650   \n",
      "1  0.051353  0.056146 -0.170191  ...  0.383646 -0.112214 -0.140789 -0.297650   \n",
      "2 -0.026189  0.011437 -0.008558  ...  0.037482 -0.138211 -0.384747 -0.361625   \n",
      "\n",
      "   mode_194  mode_195  mode_196  mode_197  mode_198  mode_199  \n",
      "0 -0.016243  0.253866 -0.138298  0.224835 -0.092936 -0.036101  \n",
      "1 -0.016243  0.253866 -0.138298  0.224835 -0.092936 -0.036101  \n",
      "2  0.070045 -0.171340  0.141226  0.074487 -0.076700  0.051153  \n",
      "\n",
      "[3 rows x 1200 columns]\n"
     ]
    }
   ],
   "source": [
    "X, y, formulae, skipped = composition.generate_features(df, \n",
    "    elem_prop='mat2vec')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these representations which can be hundreds of columns in length, we see that it went from a simple string like 'SiO2' and was turned into something rather complicated. These representations are less interpretable than a simple chemical formula, but are now mathematical vectors that represent the materials and do so with varying degrees of domain knowledge. In 2020 my group published a careful study that asked whether or not this domain knowledge was actually necessary or helpful in predicting materials properties. We essentially found that the domain knowledge does improve predictions, but as the data increases this advantage slowly disappears. \n",
    "\n",
    "You can read the article here https://doi.org/10.1007/s40192-020-00179-z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now you try it!\n",
    "Generate a list of compounds you are interested in, look up their properties, and then featurize this data with your choice of feature set to create an X input and a y target label. Try adding a broken chemical formula that includes an abbreviation for an element that doesn't exist and then see what you find in the skipped variable output by the `CBFV.generate_features` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
