{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here are some relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are going to build a simple VAE model \n",
    "### i added a zip folder with images of microstructures that we are going to use to train the model\n",
    "### they are in a folder called micrographs, make sure you downloaded this and you use this as the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, create a function that loads all your images and returns a list of paths to the images for each image.\n",
    "### so the final list, will contain a path to each image in the folder.\n",
    "### the images in the dataset contain .png, .tif, and .tiff files so make sure to specify these extensions within the function\n",
    "### Hint: load_images(data_dir) ->  [list of paths to the images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we'll want to process these images and do some transformations to the images\n",
    "### We are going to do this by creating a class called MicrographDataset that inherits from PyTorch's Dataset class\n",
    "### this class is going to take in your image_paths (the output of the load_images function) and apply transformations to the images\n",
    "### the transformations we are going to apply are a resize to 32×32 pixels and a normalization of the images [0,1]\n",
    "### and a conversion to grayscale. \n",
    "### hint: your class should have a __init__ , __len__ , __getitem__ method within it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are now ready to create a simple VAE (set the latent dimension to 8)\n",
    "### in this class, you should have an encoder and a decoder\n",
    "### Implement the ConvolutionalVAE class, inheriting from nn.Module.\n",
    "### create it using the following architecture\n",
    "\n",
    "\n",
    "### input: grayscale images of size 32×32\n",
    "### first convolutional layer: 16 filters, kernel size 3, stride 2, padding 1\n",
    "### second convolutional layer: 32 filters, kernel size 3, stride 2, padding 1\n",
    "### inbetween each convolutional layer add a ReLU activation function\n",
    "\n",
    "\n",
    "### Flatten the output of the second convolutional layer and pass it through two fully connected layers to get the mean and log variance\n",
    "### the size should be 32 x 8 x 8\n",
    "### make sure to use a linear layer to get the mean and log variance\n",
    "\n",
    "### design the decoder with the following architecture\n",
    "\n",
    "\n",
    "### fully connected layer to reshape from latent space to feature volume\n",
    "### first transposed convolution: 16 filters, kernel size 3, stride 2, padding 1\n",
    "### second transposed convolution: 1 filter, kernel size 3, stride 2, padding 1\n",
    "### final activation: Sigmoid\n",
    "\n",
    "### make sure to define the following methods within the class\n",
    "### encode(): Processes input through the encoder and returns mu and logvar\n",
    "### reparameterize(): ppplies the reparameterization for sampling\n",
    "### decode(): reconstructs images from latent vectors\n",
    "### forward(): combines the encode and decode methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we now need a loss function, define a VAE loss function called vae_loss\n",
    "\n",
    "### Calculate the binary cross-entropy between the reconstructed and original images\n",
    "### Calculate the KL divergence between the latent distribution and a standard normal\n",
    "### Combine these with a beta param = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a train function called train_vae that takes in the following parameters:\n",
    "### model, data_loader, num_epochs\n",
    "\n",
    "\n",
    "### use the Adam optimizer with lr = 1e-3\n",
    "### try different number of epochs and learning rates to see how the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a function called generate_similar_images() that takes a the trained VAE model and an original micrograph image, then generates multiple similar but non-identical variations of the original image by adding noise in the latent space\n",
    "### you'll want to encode the original image to get the mean and log variance, then sample from the distribution to get a new latent vector\n",
    "### add noise to the latent vector and decode it to get the 5 new images\n",
    "### hint: the function should take in a model, an orignal image, and the number of images to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the training and plot the loss curve with respect to epochs\n",
    "### generate 5 similar images for a random image in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next we are going to train the crabnet model on a shearmodulus dataset\n",
    "### repo: https://github.com/anthony-wang/CrabNet\n",
    "### download the shearmodulus dataset on canvas. \n",
    "### train the crabnet model on the dataset and plot the loss curve with respect to epochs\n",
    "### make sure to prepare the dataset and use a CBFV to featuize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the model on a 10% test set and calculate the mean squared error of the model print the MSE value below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the trained model to predict the shearmodulus on the following materials composititions\n",
    "###  new_materials = [\n",
    "        \"Fe2O3\",\n",
    "        \"TiO2\",\n",
    "        \"Al2O3\",\n",
    "        \"SiO2\",\n",
    "        \"ZnO\",\n",
    "        \"CaTiO3\",\n",
    "        \"Li4Ti5O12\",\n",
    "        \"BaTiO3\",\n",
    "        \"LiFePO4\",\n",
    "        \"MgAl2O4\"\n",
    "###    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put the predicted values in a dictionary with the material name as the key and the predicted value as the value\n",
    "### print the dictionary below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
